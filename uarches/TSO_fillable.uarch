% Legend:
% "/\" = AND
% "\/" = OR
% "~"  = NOT
% "=>" = IMPLIES
% "%"  = COMMENT
%
% Graph node = (instruction, [(pipeline,] stage number[)])
% Graph edge = (node, node, label)
%
% "c" is predefined to be the core ID

% To convert the SC uarch to the TSO uarch, you will need to do the following:
%
% 1. Add StoreBuffer and MemoryHierarchy stages to the microarchitecture.
% 2. Split the Instr_Path axiom into two axioms, one for reads and one for writes.
%    Writes go through the store buffer and reach memory, reads do not.
% 3. Enforce that writes on the same core go through the store buffer in program order.
% 4. Modify the WriteSerialization and EnforceFinalWrite axioms to enforce coherence order
%    at the MemoryHierarchy stage rather than the Writeback stage.
% 5. Modify the EnforceWritePPO axiom to ensure that a write is only released from the
%    store buffer after all prior writes from that core have reached memory.
% 6. Ensure that if a load is reading from memory, that core's store buffer has
%    no entries for the address of the load. This includes modifying the macros
%    that comprise Read_Values to enforce orderings on writes at the MemoryHierarchy stage
%    rather than the Writeback stage.
% 7. (Advanced) Allow a core to read the value of a write from its store buffer,
%    before that write is made visible to other cores.
% 8. (Extra) Implement a fence operation that flushes all prior writes to
%    memory before any succeeding instructions can perform.

StageName 0 "Fetch".
StageName 1 "Execute".
StageName 2 "Writeback".

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 1. Add StoreBuffer and MemoryHierarchy stages to the microarchitecture.     %
%                                                                             %
% Add a "StoreBuffer" stage (stage 3) and a "MemoryHierarchy" stage (stage 4) %
% to represent stores reaching the store buffer and memory respectively.      %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

StageName _ "___________".
StageName _ "_______________".

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END MODIFICATION REGION                                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 2. Split the Instr_Path axiom into two axioms, one for reads and one for    %
%    writes. Writes go through the store buffer and reach memory, reads do    %
%    not.                                                                     %
%                                                                             %
% -Fill in the blanks in the Writes_Path axiom so that after Writeback,       %
%  writes go to the core's StoreBuffer and from there to MemoryHierarchy.     %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Axiom "Reads_Path":
forall microops "i",
IsAnyRead i =>
AddEdges [((i, Fetch),      (i, Execute),     "path");
          ((i, Execute),     (i, Writeback),    "path")].

Axiom "Writes_Path":
forall microops "i",
IsAnyWrite i =>
AddEdges [((i, Fetch),      (i, Execute),     "path");
          ((i, Execute),     (i, Writeback),    "path");
          ((i, _________),     (i, ___________),    "path");
          ((i, ___________),     (i, _______________),    "path")
          ].

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END MODIFICATION REGION                                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Axiom "PO_Fetch":
forall microops "i1",
forall microops "i2",
SameCore i1 i2 /\ ProgramOrder i1 i2 =>
AddEdge ((i1, Fetch), (i2, Fetch), "PO", "blue").

Axiom "Execute_stage_is_in_order":
forall microops "i1",
forall microops "i2",
SameCore i1 i2 /\ EdgeExists ((i1, Fetch),  (i2, Fetch), "") =>
AddEdge ((i1, Execute), (i2, Execute), "PPO", "darkgreen").

% Note: This enforces ordering at WB if ordering is enforced at IF.
Axiom "Writeback_stage_is_in_order":
forall microops "i1",
forall microops "i2",
SameCore i1 i2 /\ EdgeExists ((i1, Fetch),  (i2, Fetch), "") =>
AddEdge ((i1, Writeback), (i2, Writeback), "PPO", "darkgreen").

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3. Ensure that writes from the same core go through the store buffer in     %
%    program order.                                                           %
%                                                                             %
% Add an axiom below to enforce that if two writes go through the             %
% Writeback stage in order, then they go through the store buffer in order    %
% as well.                                                                    %
%                                                                             %
% Hint: You can use the Writeback_stage_is_in_order axiom above as a starting %
%       point, but remember that this axiom should only apply to pairs of     %
%       writes.                                                               %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Axiom "StoreBuffer_stage_is_in_order":
forall microops "i1",
forall microops "i2",
__________ i1 /\ __________ i2 /\ SameCore i1 i2 /\ EdgeExists ((i1, _________),  (i2, _________), "") =>
AddEdge ((i1, ___________), (i2, ___________), "PPO", "darkgreen").

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END MODIFICATION REGION                                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 4. Modify the WriteSerialization and EnforceFinalWrite axioms to enforce    %
%    orderings on writes at the MemoryHierarchy stage rather than the         %
%    Writeback stage.                                                         %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Axiom "WriteSerialization":
forall microops "i1",
forall microops "i2",
    ( ~(SameMicroop i1 i2) /\ IsAnyWrite i1 /\ IsAnyWrite i2 /\ SamePhysicalAddress i1 i2) =>
    (EdgeExists ((i1, _______________), (i2, _______________), "ws", "red") \/
     EdgeExists ((i2, _______________), (i1, _______________), "ws", "red")).

Axiom "EnforceFinalWrite":
  forall microop "w",
  forall microop "w'",
  (IsAnyWrite w /\ IsAnyWrite w' /\ SamePhysicalAddress w w' /\
   ~SameMicroop w w' /\ DataFromFinalStateAtPA w') =>
      AddEdge ((w, _______________), (w', _______________), "ws_final", "red").

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END MODIFICATION REGION                                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 5. Ensure that a write is only released from the store buffer after all     %
%    prior writes from that core have reached memory.                         %
%                                                                             %
% Modify the axiom below to enforce that if a write w is fetched before a     %
% write w' on the same core, then the first write (w) reaches memory before   %
% the second one (w') can leave the store buffer.                             %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Axiom "EnforceWritePPO":
  forall microop "w",
  forall microop "w'",
  (IsAnyWrite w /\ IsAnyWrite w' /\ SameCore w w' /\ EdgeExists((w, Fetch), (w', Fetch), "")) =>
      AddEdge ((w, _______________), (w', ___________), "EWO", "green").

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END MODIFICATION REGION                                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Constraints on values read by loads follow.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 6. Ensure that if a load is reading from memory, that core's store buffer   %
%    has no entries for the address of the load.                              %
%                                                                             %
% Create a macro below to enforce that all writes before an instruction "i"   %
% in program order that write to the address of "i" have reached memory       %
% before the Execute stage of instruction "i".                                %                           %
%                                                                             %
% Remember that since this is a macro, it will not affect execution unless it %
% is included in an axiom through the use of "ExpandMacro <macro name>".      %
% Thus, expand this macro appropriately in the Read_Values axiom near the     %
% end of the file. See the instructions above the Read_Values axiom for more  %
% details.                                                                    %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DefineMacro "STBEmpty":
  % Store buffer is empty for the address we want to read.
  forall microop "w", (
    (IsAnyWrite w /\ SamePhysicalAddress w i /\ ProgramOrder w i) =>
    AddEdge ((w, _______________), (i, _______), "STBEmpty", "purple")).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END MODIFICATION REGION                                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 6. (Contd.) Modify the three macros below that comprised SC_fillable's      %
%    Read_Values axiom to enforce orderings on                                %
%    writes with respect to the MemoryHierarchy stage rather than the         %
%    Writeback stage.                                                         %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DefineMacro "BeforeAllWrites":
  % Read occurs before all writes to same PA & Data
  DataFromInitialStateAtPA i /\
  forall microop "w", (
    (IsAnyWrite w /\ SamePhysicalAddress w i /\ ~SameMicroop i w) =>
    AddEdge ((i, Execute), (w, _______________), "fr", "red")).

DefineMacro "Before_Or_After_Every_SameAddrWrite":
  % Either before or after every write to the same physical address
  forall microop "w", (
    (IsAnyWrite w /\ SamePhysicalAddress w i) =>
    (AddEdge ((w, _______________), (i, Execute), "wsrf", "crimson") \/
     AddEdge ((i, Execute), (w, _______________), "fr", "red"))).

DefineMacro "No_SameAddrWrites_Btwn_Src_And_Read":
  % Read from "w", and there must not exist any writes w' in between w and i
  exists microop "w", (
    IsAnyWrite w /\ SamePhysicalAddress w i /\ SameData w i /\
    AddEdge ((w, _______________), (i, Execute), "rf", "red") /\
    ~(exists microop "w'",
      IsAnyWrite w' /\ SamePhysicalAddress i w' /\ ~SameMicroop w w' /\
      EdgesExist [((w , _______________), (w', _______________), "");
                  ((w', _______________), (i, Execute), "")])).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END MODIFICATION REGION                                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 6. (Contd.) Invoke the STBEmpty macro to enforce that if a load is reading  %
%    from memory, the store buffer of that core has no entries for the load's %
%    address.                                                                 %
%                                                                             %
% The axiom below enforces (by expanding macros) that a load must either      %
% (a) occur before all writes, or                                             %
% (b) read from the latest write to that address, and be ordered with respect %
%     to every write to that address.                                         %
%                                                                             %
% In all cases of the current axiom below, the load reads from memory.        %
% Modify the axiom to enforce that whenever a core reads from memory, its     %
% store buffer has no entries for the address of the load (by expanding the   %
% STBEmpty macro).                                                            %
%                                                                             %
% If you decide to do the Advanced portion of this hands-on (store buffer     %
% forwarding), uncomment the macro expansion detailing forwarding from the    %
% store buffer as an alternate option to the cases of reading from memory     %
% that are currently below.                                                   %        %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Axiom "Read_Values":
forall microops "i",
IsAnyRead i =>
(
% Uncomment the commented lines if you add the (advanced) store buffer forwarding.
%  ExpandMacro ______ \/
%  (
       ExpandMacro ________ /\
       (
          ExpandMacro BeforeAllWrites
          \/
          (
            ExpandMacro No_SameAddrWrites_Btwn_Src_And_Read
            /\
            ExpandMacro Before_Or_After_Every_SameAddrWrite
          )
       )
%  )
).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END MODIFICATION REGION                                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 7. (Advanced) Allow a core to read the value of a write from its store      %
%    buffer, before that write is made visible to other cores.                %
%                                                                             %
% Add a macro below that checks for a write to the same address with the same %
% data as a load instruction "i" on the same core as the write, and adds      %
% edges from the Execute stage of the write to the Execute stage of the load  %
% (to reflect forwarding in the pipeline and store buffer) and from the       %
% Execute stage of the load to when the store reaches memory (since           %
% forwarding from the store buffer must occur before the write leaves the     %
% store buffer and reaches memory.                                            %
%                                                                             %
% The macro must also check that there are no writes to the same address in   %
% program order between the forwarding write and the load. This is necessary  %
% because any forwarding must occur from the latest write to a given address  %
% before the load.                                                            %
%                                                                             %
% After completing this, go back to the Read_Values axiom above and uncomment %
% the commented lines that expand the STBFwd macro. This will allow loads to  %
% read their value from the store buffer as well as from memory.              %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DefineMacro "STBFwd":
  % Forward from the store buffer
  exists microop "w", (
    __________ w /\
    ________ w i /\
    ___________________ w i /\
    ________ w i /\
    AddEdges [((w, Execute), (i, Execute), "STBFwd", "red");
              ((i, Execute), (w, MemoryHierarchy), "STBFwd", "purple")]) /\
    % Ensure the STB entry is the latest one.
    ~exists microop "w'",
    __________ w' /\ ___________________ w w' /\
    ____________ w w' /\ ____________ w' i.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END MODIFICATION REGION                                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             %
% 8. (Extra) Implement a fence operation that flushes all prior writes to     %
%    memory before any succeeding instructions can perform.                   %
%                                                                             %
% Add an axiom below detailing the operations of a fence instruction which    %
% can be used for synchronization between threads. The fence should have      %
% three stages: Fetch, Execute, and Writeback. In addition, the fence should  %
% ensure that all writes prior to the fence in program order must reach       %
% memory before the Execute stage of the fence.                               %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Axiom "Fence_Ordering":
forall microops "f",
IsAnyFence f =>
AddEdges [((f, Fetch),       (f, Execute),      "path");
          ((f, Execute),     (f, Writeback), "path")]
/\
(
  forall microops "w",
    (__________ w /\ ____________ w f) =>
      AddEdge ((w, _______________), (f, _______), "fence", "orange")
).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END MODIFICATION REGION                                                     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
